---
title: "test"
author: "Collin"
date: "9/25/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggthemes)
library(discreteRV)
```



```{r}
qnorm(.6)

#sample from a normal distribution with mean 0, sd 1

sample_0 = rnorm(1000000)

x1<-seq(-5,7, 0.01)
y1<-dnorm(x1,0,1)
x2 = seq(-7,7,.01)
y2 = dnorm(x2,3,1)

x1_data = data_frame(x1,y1)
x2_data = data_frame(x2,y2)


powerr = .8

qnorm(powerr)


ggplot(data = x1_data) +
  geom_line(data = x1_data, mapping = aes(x = x1, y = y1), color = "blue")+
  geom_line(data = x2_data, mapping = aes(x = x2, y = y2), color = "red")+
  geom_ribbon(data= x1_data %>% filter(x1 <= qnorm(powerr)), x = x1, aes(ymax=y1),ymin=0,
              fill="blue",colour=NA,alpha=0.5)+
  geom_vline(xintercept = 0, color = "blue", linetype = "dashed") +
  geom_vline(xintercept = 3, color = "red", linetype = "dashed") +
  scale_x_continuous(breaks = seq(-7, 7, by = 1))+
  ylab("") +
  scale_y_continuous(breaks = NULL)+
  ggtitle("Normal Distributions")+
  theme_minimal()+
  theme(plot.title = element_text(size = 20, face = 'bold'))


?stat_function

qnorm(.5)
```


```{r}

install.packages('Ryacas') 
library('Ryacas') 
yac_expr("Integrate(x)  Exp(-(lamb*x))") 

test = yac_expr("D(x) x^2 + 4*x")


install.packages("ReIns")
library(ReIns)

n = 5
for(i in 1:5){
  print(i)
}

test_vec = vector(mode = "numeric", length = n)
test_vec
```



```{r}
# choose parameters: c, lambda, n 
# sample thousands of observations from T's distribution and then observe it's variance



#create function to generate/sample observations from T's distribution
sample_T = function(n, c, lambda){
  #first sample from a truncated exponential distribution, Random Variable X
  X = rexp(n,rate = lambda)
  
  #create a vector to store values drawn from T's distribution: T = min(X,c)
  rv_T = vector(mode = "numeric", length = n) #this is more efficient than creating an empty vector and then                                                      #lengthening it with every iteration in the following for loop
  
  for(i in 1:n){
    rv_T[i] = min(X[i],c) #generate observation and assign it to the ith elemtn in the rv_T vector 
  }
  return(rv_T)
  
}

```


```{r}
#generate values from T
set.seed(1)
n = 100000
c = 1
lambda = 10
random_sample_T = sample_T(n = n,c = c, lambda = lambda)
hist(random_sample_T)

ggplot(mapping = aes(random_sample_T))+
  geom_histogram(bin_width = .5, color = "black", fill = "lightblue", alpha = .6)+
  geom_density()+
  theme_minimal()+
  ggtitle("Random Sample of T = min(X,c)", subtitle = str_glue("c = {c}", c = c))

```



```{r}
#calculate the variance (don't consider sample variance)
set.seed(1)
var_T = mean((random_sample_T - mean(random_sample_T))^2)
var_T

simulated_variance = mean(random_sample_T^2) - (mean(random_sample_T))^2



```


```{r}

set.seed(1)

#define global parameters c and lambda
lambda = 10
c = 1


#This is the E(T|M = X): X < c /isGreater = 0
E_t_given_mequals_x = function(x){
  x*lambda*exp(-lambda*x)/(1 - exp(-lambda*c)) #appears correct when compared to ti89 output
}


#This is Var(T|M = X) (when M = c the variance is 0)
var_t_given_mequals_x = function(x){
  (x^2*lambda*exp(-lambda*x))/(1 - exp(-lambda*c)) - (integrate(E_t_given_mequals_x,0,c)$value)^2  #appears correct when compared to ti89 output, the second moment - the mean squared
}



#important probabilities



prob_m_equals_c = exp(-lambda*c) # P(X > c) = P(isGreater = 1)
prob_m_equals_X = 1 - exp(-lambda*c) #P(X<= c) = P(isGreater = 0)
var_T = function(){
  #calculate E[Var(T|M)] . The way i Think about it is, Var(T|M) is a discrete random variable that takes on two possible
  #values. it takes on the value 0 with probability P(M = c) (this is equivalent to isGreater = 1),
  # it takes on another more complicated value [ (T | M = X ) (this is equivakent to isGreater = 0) , this requires integration
  #over the exponential random variable's PDF
  E_var = 0^2*prob_m_equals_c + integrate(var_t_given_mequals_x,0,c)$value * prob_m_equals_X
  
  #calculate Var[E(T|M)]
  second_moment = c^2*prob_m_equals_c + integrate(var_t_given_mequals_x,0,c)$value*prob_m_equals_X
    
  mean_squared = (c*prob_m_equals_c + integrate(E_t_given_mequals_x,0,c)$value*prob_m_equals_X)^2
  
  var_E = second_moment - mean_squared
  
  
  return(list(E_var, var_E, E_var + var_E))
  
}



calculated_variance = var_T()[[3]] #this is the total variance of T

#compare calculated variance to simulated variance


calculated_variance/simulated_variance #veryyyyy close


```



```{r}
#calculate the E(T|X<c)

#calculate the E(Q^2)


rbinom(10,20,.5)

```





```{r}
#create 3 Discrete random variables A,B,C 
W = RV(c(-3,3))

A = RV(c(1,2,3), probs = c(.5,.25,.25))
B = RV(c(4,5,6), probs = c(.5,.25,.25))
C = RV(c(7,8,9), probs = c(.5,.25,.25))

#create random variables U and V, note U and V will not be independent because they both depend on C
U = A + C

V = B + C

#create the random variable Y
Y = U + V + W

Y

#sample from A,B,C

#generate A values
gen_A = function(n){
  realized_As = numeric(n)
  uniform_values = runif(n)
  
  for(i in 1:n){
    # 0-.5 make the outcome 1
    if(uniform_values[i] < .5){
      realized_As[i] = 1
    }
    else if(uniform_values[i] <.75){
      realized_As[i] = 2
    }
    else{ #uniform_values < 1 and > .75
      realized_As[i] = 3
    }
    
    #.5-.75 make the outcome 2
    
    #.75 - 1 make the outcome 3
    
  }
  return(realized_As)
}

gen_B = function(n){
  realized_Bs = numeric(n)
  uniform_values = runif(n)
  
  for(i in 1:n){
    # 0-.5 make the outcome 1
    if(uniform_values[i] < .5){
      realized_Bs[i] = 4
    }
    else if(uniform_values[i] <.75){
      realized_Bs[i] = 5
    }
    else{ #uniform_values < 1 and > .75
      realized_Bs[i] = 6
    }
    
    #.5-.75 make the outcome 2
    
    #.75 - 1 make the outcome 3
    
  }
  return(realized_Bs)
}

gen_C = function(n){
  realized_Cs = numeric(n)
  uniform_values = runif(n)
  
  for(i in 1:n){
    # 0-.5 make the outcome 1
    if(uniform_values[i] < .5){
      realized_Cs[i] = 7
    }
    else if(uniform_values[i] <.75){
      realized_Cs[i] = 8
    }
    else{ #uniform_values < 1 and > .75
      realized_Cs[i] = 9
    }
    
    #.5-.75 make the outcome 2
    
    #.75 - 1 make the outcome 3
    
  }
  return(realized_Cs)
}

gen_W = function(n){
  realized_Ws = numeric(n)
  uniform_values = runif(n)
  
  for(i in 1:n){
    
    if(uniform_values[i] < .5){
      realized_Ws[i] = -3
    }
    else{
      realized_Ws[i] = 3
    }
  
  }
  return(realized_Ws)
}


set.seed(1)
vectorA = gen_A(25)

set.seed(2)
vectorB = gen_B(25)

set.seed(3)
vectorC = gen_C(25)
vectorW = gen_W(25)

table(vectorA + vectorC)

vectorU = vectorA + vectorC
vectorV = vectorB + vectorC
sample_data = data.frame(U = vectorA + vectorC, 
                         V = vectorB + vectorC,
                         W = vectorW
                         )

sample_data %>% 
  select(U) %>% 
  group_by(U) %>% 
  summarise(number_u = n())

sample_data

```


#Sample Data Generation
```{r}
library(tidyverse)

#Draw samples from these Discrete distributions
set.seed(1)
A_sample = sample(c(1,2,3), size = 25, prob = c(.5,.25,.25), replace = TRUE)

set.seed(2)
B_sample = sample(c(4,5,6), size = 25, prob = c(.5,.25,.25), replace = TRUE)

set.seed(3)
C_sample = sample(c(7,8,9), size = 25, prob = c(.5,.25,.25), replace = TRUE)
W_sample = sample(c(-3,3), size = 25, prob = c(.5,.5), replace = TRUE)


#now create U and V vectors: #then have Y = U + V + W
#and create a dataframe of the data
sampled_data = data.frame(U = A_sample + C_sample,
                          V = B_sample + C_sample,
                          W = W_sample,
                          Y = A_sample +C_sample + B_sample + C_sample + W_sample)


sampled_data %>% 
  select(U) %>% 
  group_by(U) %>% 
  summarise(counts = n()) %>% 
  mutate(prop = counts/sum(counts))
sampled_data %>% 
  filter(U == 10)


#given U = 10, what is mean of Y? E(Y| U = 10)
sampled_data %>% 
  filter(U == 10) %>% 
  summarise(mean_Y = mean(Y))
  
  
sampled_data %>% 
  filter(U == 10) %>% 
  group_by(U,V) %>% 
  summarise(counts = n()) %>% 
  mutate(prop = counts/sum(counts))
```

#RHS and LHS calculations
```{r}
#verified by hand in the example case of U = 10 that E[E(U,V)|U = 10] = E(Y|U = 10). now show it for all values of U
#calculate RHS and LHS separately, then throw them in a dataframe together and visually inspect them, or just test for equivalence
#Let RHS = E(Y|U = i)

RHS = numeric() #initialize vector of specified length (technically more efficient)

#loop over every value of U and calculate E(Y|U = i)
for(i in unique(sampled_data$U)){
  #subset the data properly, ie, condition on U = i
  Y_given_U = sampled_data %>% 
    filter(U == i)
  RHS = c(RHS,mean(Y_given_U$Y))

}




#Let LHS = E[E(Y|U,V)|U = i] 

LHS = numeric()
for(i in unique(sampled_data$U)){
  
  #create a dataframe which is basically E(Y|U = i, V) (a discrete random variable with condition expectations as its values)
  tower_prop = sampled_data %>% filter(U == i) %>% 
  group_by(U,V) %>% 
  summarise(counts = n(), mean_Y = mean(Y)) %>% 
  mutate(props = counts / sum(counts))

 double_e_given_some_U = sum(tower_prop$mean_Y*tower_prop$props) #this is the tower property calculation for the ith U
 
 #append it to the LHS vector
 LHS = c(LHS, double_e_given_some_U)
 
}


#add LHS and RHS to a dataframe and compare
simulation_comp_df = data.frame(U = unique(sampled_data$U), tower_prop_LHS = LHS, E_Y_given_U_RHS = RHS)
simulation_comp_df




```



```{r}
#write a function for the CDF of W
#E(X | X <= 1) 

dbinom(1,2,.2)/pbinom(1,2,.2)


```









